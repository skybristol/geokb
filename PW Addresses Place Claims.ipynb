{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook works back through the PW baseline to add \"addresses place\" claims based on PW Catalog metadata for countries, states, and counties that can be confidently matched to established items in the GeoKB. We are ignoring cities for the time being because a) I've not yet pulled any of those into the GeoKB and b) the PW metadata is pretty poor as it does not indicate what state or country the cities are in. We could use the context of any country/state/county combinations to get close on some records, but we'll deal with that down the road at some point.\n",
    "\n",
    "The otherGeospatial field from the PW Catalog is potentially even more interesting in that it can contain other geographic place names beyond administrative boundaries. This is another area I need to work through at some point, but we'll have to compare the quality of the metadata with what we can extract from full texts. For now, I'm ignoring this field.\n",
    "\n",
    "I place this information using the \"addresses subject\" predicate based on a presumption that that is what the metadata means - the article/report has something in it that addresses the named place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sqlalchemy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwbmaker\u001b[39;00m \u001b[39mimport\u001b[39;00m WikibaseConnection\n",
      "File \u001b[0;32m~/wbmaker.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwikibaseintegrator\u001b[39;00m \u001b[39mimport\u001b[39;00m models, datatypes\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwikibaseintegrator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwbi_enums\u001b[39;00m \u001b[39mimport\u001b[39;00m WikibaseDatatype, ActionIfExists, WikibaseDatePrecision\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m \u001b[39mimport\u001b[39;00m create_engine\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmwclient\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mWikibaseConnection\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sqlalchemy'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from wbmaker import WikibaseConnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "geokb = WikibaseConnection('GEOKB_CLOUD')\n",
    "\n",
    "# Working with a cached dump of USGS Numbered Series\n",
    "pw_dump = pd.DataFrame(pickle.load(open('data/pw_usgs_reports_dump.pickle', 'rb')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get PW IDs\n",
    "\n",
    "I'm running the whole process as a batch to establish a baseline of PW items in the GeoKB. To build out a batch of claims for places, I need to get the mapping of GeoKB QID to PW indexId. There is a current issue in the SPARQL query not returning all the items it should be. To compensate, I've run a handful of queries to pull out more of the items, stashing those into a few files stored temporarily on the MPC hub where I'm running this code. The following codeblock pulls all of that together to create an ID map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "geokb_pw_ids = geokb.url_sparql_query(\n",
    "    sparql_url=\"https://geokb.wikibase.cloud/query/sparql?query=PREFIX%20wd%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fentity%2F%3E%0APREFIX%20wdt%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fprop%2Fdirect%2F%3E%0A%0ASELECT%20%3Fitem%20%3FindexId%0AWHERE%20%7B%0A%20%20%3Fclasses%20wdt%3AP2%20wd%3AQ11%20.%0A%20%20%3Fitem%20wdt%3AP1%20%3Fclasses%20.%0A%20%20%3Fitem%20wdt%3AP114%20%3FindexId%20.%0A%7D\",\n",
    "    output_format=\"dataframe\"\n",
    ")\n",
    "\n",
    "geokb_pw_ids[\"qid\"] = geokb_pw_ids['item'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "id_dfs = [\n",
    "    geokb_pw_ids.drop(columns=['item'])\n",
    "]\n",
    "\n",
    "# Workaround for partial failure state in SPARQL\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "for fn in glob('./data/extra_pwids/*'):\n",
    "    cached_ids = pd.DataFrame(json.load(open(fn)))\n",
    "    cached_ids['qid'] = cached_ids['item'].apply(lambda x: x.split('/')[-1])\n",
    "    id_dfs.append(cached_ids.drop(columns=['item']))\n",
    "\n",
    "id_map = pd.concat(id_dfs)\n",
    "\n",
    "id_map.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoNames\n",
    "\n",
    "Here I tease out the country and state fields from the PW dump and set those up for easier processing. Some records list multiple, so I split those into lists and then explode them for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_geo_names(name_string):\n",
    "    if not isinstance(name_string, str):\n",
    "        return\n",
    "    delim = \",\"\n",
    "    if \";\" in name_string:\n",
    "        delim=';'\n",
    "\n",
    "    return [i.strip() for i in name_string.split(delim)]\n",
    "\n",
    "pw_geo_name_props = [\n",
    "    \"indexId\",\n",
    "    \"country\",\n",
    "    \"state\"\n",
    "]\n",
    "\n",
    "pw_geo_names = pw_dump[pw_geo_name_props].dropna(subset=[i for i in pw_geo_name_props if i != 'indexId'], how=\"all\")\n",
    "pw_geo_names['country'] = pw_geo_names['country'].apply(split_geo_names)\n",
    "pw_geo_names['state'] = pw_geo_names['state'].apply(split_geo_names)\n",
    "\n",
    "dfs = []\n",
    "for name_class in pw_geo_name_props:\n",
    "    if name_class != 'indexId':\n",
    "        class_df = pw_geo_names[pw_geo_names[name_class].str.len() > 0][['indexId',name_class]].explode(name_class).rename(columns={name_class: 'place_name'}).reset_index(drop=True)\n",
    "        class_df['name_type'] = name_class\n",
    "        dfs.append(class_df)\n",
    "\n",
    "pw_classed_geo_names = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indexId</th>\n",
       "      <th>place_name</th>\n",
       "      <th>name_type</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ofr20231045</td>\n",
       "      <td>United States</td>\n",
       "      <td>country</td>\n",
       "      <td>Q161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ofr20231052</td>\n",
       "      <td>United States</td>\n",
       "      <td>country</td>\n",
       "      <td>Q161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sir20235079</td>\n",
       "      <td>United States</td>\n",
       "      <td>country</td>\n",
       "      <td>Q161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fs20233030</td>\n",
       "      <td>United States</td>\n",
       "      <td>country</td>\n",
       "      <td>Q161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir20235042</td>\n",
       "      <td>United States</td>\n",
       "      <td>country</td>\n",
       "      <td>Q161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       indexId     place_name name_type object\n",
       "0  ofr20231045  United States   country   Q161\n",
       "1  ofr20231052  United States   country   Q161\n",
       "2  sir20235079  United States   country   Q161\n",
       "3   fs20233030  United States   country   Q161\n",
       "4  sir20235042  United States   country   Q161"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pw_countries = pw_classed_geo_names[pw_classed_geo_names['name_type'] == 'country']\n",
    "\n",
    "# Get country reference from the GeoKB\n",
    "geokb_countries = geokb.url_sparql_query(\n",
    "    sparql_url=\"https://geokb.wikibase.cloud/query/sparql?query=PREFIX%20wdt%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fprop%2Fdirect%2F%3E%0A%0ASELECT%20%3Fitem%20%3FitemLabel%20%3Fitem_alt_label%20%3Fiso_country_code%0AWHERE%20%7B%0A%20%20%3Fitem%20wdt%3AP38%20%3Fiso_country_code%20.%0A%20%20OPTIONAL%20%7B%0A%20%20%20%20%3Fitem%20skos%3AaltLabel%20%3Fitem_alt_label%20.%0A%20%20%20%20FILTER%20(lang(%3Fitem_alt_label)%3D'en')%0A%20%20%7D%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22en%22%20.%20%7D%0A%7D\",\n",
    "    output_format=\"dataframe\"\n",
    ")\n",
    "geokb_countries[\"object\"] = geokb_countries['item'].apply(lambda x: x.split('/')[-1])\n",
    "country_lookup = pd.concat([\n",
    "    geokb_countries[['object','itemLabel']].drop_duplicates().rename(columns={'itemLabel': 'country_name'}),\n",
    "    geokb_countries[['object','item_alt_label']].dropna().rename(columns={'item_alt_label': 'country_name'}),\n",
    "])\n",
    "country_lookup.drop_duplicates(inplace=True)\n",
    "\n",
    "# Build country claims\n",
    "country_claims = pd.merge(\n",
    "    left=pw_classed_geo_names[pw_classed_geo_names['name_type'] == 'country'],\n",
    "    right=country_lookup[['object','country_name']].rename(columns={'country_name': 'place_name'}),\n",
    "    how=\"inner\",\n",
    "    on=\"place_name\"\n",
    ")\n",
    "\n",
    "country_claims.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# States/Provinces\n",
    "\n",
    "The majority of \"state\" strings in the PW Catalog are for the U.S. along with some for Canada and Mexico. While there are other strings that could be useful, I have not yet incorporated first-level subdivisions for any other countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indexId</th>\n",
       "      <th>place_name</th>\n",
       "      <th>name_type</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ofr20231052</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>state</td>\n",
       "      <td>Q254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ofr20231049</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>state</td>\n",
       "      <td>Q254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sir20235039</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>state</td>\n",
       "      <td>Q254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sir20235029</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>state</td>\n",
       "      <td>Q254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir20225099</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>state</td>\n",
       "      <td>Q254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       indexId place_name name_type object\n",
       "0  ofr20231052     Alaska     state   Q254\n",
       "1  ofr20231049     Alaska     state   Q254\n",
       "2  sir20235039     Alaska     state   Q254\n",
       "3  sir20235029     Alaska     state   Q254\n",
       "4  sir20225099     Alaska     state   Q254"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pw_states = pw_classed_geo_names[pw_classed_geo_names['name_type'] == 'state']\n",
    "\n",
    "# Get state, territory, province references from the GeoKB for US, CA, and MX\n",
    "geokb_state_entities = geokb.url_sparql_query(\n",
    "    sparql_url=\"https://geokb.wikibase.cloud/query/sparql?query=PREFIX%20wd%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fentity%2F%3E%0APREFIX%20wdt%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fprop%2Fdirect%2F%3E%0A%0ASELECT%20%3Fitem%20%3FitemLabel%0AWHERE%20%7B%0A%20%20%3Fitem%20wdt%3AP1%20%3Fstate_classes%20.%0A%20%20VALUES%20%3Fstate_classes%20%7B%20wd%3AQ138361%20wd%3AQ138360%20wd%3AQ138362%20wd%3AQ229%20wd%3AQ25363%20%7D%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22en%22%20.%20%7D%0A%7D\",\n",
    "    output_format=\"dataframe\"\n",
    ")\n",
    "\n",
    "geokb_state_entities['object'] = geokb_state_entities['item'].apply(lambda x: x.split('/')[-1])\n",
    "geokb_state_entities.drop(columns='item', inplace=True)\n",
    "\n",
    "state_claims = pd.merge(\n",
    "    left=pw_states,\n",
    "    right=geokb_state_entities.rename(columns={'itemLabel': 'place_name'}),\n",
    "    how=\"inner\",\n",
    "    on=\"place_name\"\n",
    ")\n",
    "\n",
    "state_claims.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counties\n",
    "\n",
    "County references are problematic in the PW Catalog because they are simple text strings with no specific context or identifiers. To deal with this, I run through and only use items where there are both state and county lists, build strings that match how I labeled these in the GeoKB (e.g., Mesa County, Colorado), and then only make connections where I have an exact match on those strings. This cuts out a bunch of misspellings and other issues, but those are all suspect anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indexId</th>\n",
       "      <th>place_name</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ofr20231047</td>\n",
       "      <td>Kern County, California</td>\n",
       "      <td>Q51311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ofr20231014</td>\n",
       "      <td>Kern County, California</td>\n",
       "      <td>Q51311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ofr20201116</td>\n",
       "      <td>Kern County, California</td>\n",
       "      <td>Q51311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ofr20191114</td>\n",
       "      <td>Kern County, California</td>\n",
       "      <td>Q51311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ofr20161181</td>\n",
       "      <td>Kern County, California</td>\n",
       "      <td>Q51311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       indexId               place_name  object\n",
       "0  ofr20231047  Kern County, California  Q51311\n",
       "1  ofr20231014  Kern County, California  Q51311\n",
       "2  ofr20201116  Kern County, California  Q51311\n",
       "3  ofr20191114  Kern County, California  Q51311\n",
       "4  ofr20161181  Kern County, California  Q51311"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def county_states(x):\n",
    "    place_names = []\n",
    "    for state in x['states']:\n",
    "        for county in x['counties']:\n",
    "            place_names.append(f\"{county}, {state}\")\n",
    "    return place_names\n",
    "\n",
    "pw_counties = pw_dump[['indexId','county','state']].reset_index(drop=True)\n",
    "pw_counties.dropna(subset=['county','state'], inplace=True)\n",
    "pw_counties['counties'] = pw_counties['county'].apply(lambda x: [i.strip() for i in x.split(',')])\n",
    "pw_counties['states'] = pw_counties['state'].apply(lambda x: [i.strip() for i in x.split(',')])\n",
    "pw_counties.drop(columns=['state','county'], inplace=True)\n",
    "\n",
    "pw_counties['place_name'] = pw_counties.apply(county_states, axis=1)\n",
    "pw_counties = pw_counties[['indexId','place_name']].explode(\"place_name\").reset_index(drop=True)\n",
    "\n",
    "# Get county references from the GeoKB for the U.S.\n",
    "geokb_county_entities = geokb.url_sparql_query(\n",
    "    sparql_url=\"https://geokb.wikibase.cloud/query/sparql?query=PREFIX%20wd%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fentity%2F%3E%0APREFIX%20wdt%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fprop%2Fdirect%2F%3E%0A%0ASELECT%20%3Fitem%20%3FitemLabel%0AWHERE%20%7B%0A%20%20%3Fitem%20wdt%3AP1%20wd%3AQ481%20.%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22en%22%20.%20%7D%0A%7D\",\n",
    "    output_format=\"dataframe\"\n",
    ")\n",
    "\n",
    "geokb_county_entities['object'] = geokb_county_entities['item'].apply(lambda x: x.split('/')[-1])\n",
    "geokb_county_entities.drop(columns='item', inplace=True)\n",
    "\n",
    "# Build the claims\n",
    "county_claims = pd.merge(\n",
    "    left=pw_counties,\n",
    "    right=geokb_county_entities.rename(columns={'itemLabel': 'place_name'}),\n",
    "    how=\"inner\",\n",
    "    on=\"place_name\"\n",
    ")\n",
    "\n",
    "county_claims.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine places\n",
    "\n",
    "We only want to pull each item once, so we combine all the claims together and get them lined up with our ID map to the subject item QID in the GeoKB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indexId</th>\n",
       "      <th>object</th>\n",
       "      <th>qid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ofr20231045</td>\n",
       "      <td>Q161</td>\n",
       "      <td>Q55218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ofr20231045</td>\n",
       "      <td>Q161</td>\n",
       "      <td>Q55218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ofr20231052</td>\n",
       "      <td>Q161</td>\n",
       "      <td>Q55220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ofr20231052</td>\n",
       "      <td>Q254</td>\n",
       "      <td>Q55220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ofr20231052</td>\n",
       "      <td>Q161</td>\n",
       "      <td>Q55220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       indexId object     qid\n",
       "0  ofr20231045   Q161  Q55218\n",
       "1  ofr20231045   Q161  Q55218\n",
       "2  ofr20231052   Q161  Q55220\n",
       "3  ofr20231052   Q254  Q55220\n",
       "4  ofr20231052   Q161  Q55220"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place_claims = pd.concat([\n",
    "    country_claims[[\"indexId\",\"object\"]],\n",
    "    state_claims[[\"indexId\",\"object\"]],\n",
    "    country_claims[[\"indexId\",\"object\"]]\n",
    "])\n",
    "\n",
    "place_claims_identified = pd.merge(\n",
    "    left=place_claims,\n",
    "    right=id_map,\n",
    "    how=\"inner\",\n",
    "    on=\"indexId\"\n",
    ")\n",
    "\n",
    "place_claims_identified.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit as addresses place claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses_place_claims = place_claims_identified[['qid','object']].groupby('qid')['object'].agg(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Q100001', ['Q161', 'Q236', 'Q161']),\n",
       " ('Q100003', ['Q161', 'Q256', 'Q161']),\n",
       " ('Q100007', ['Q161', 'Q276', 'Q268', 'Q161']),\n",
       " ('Q100013', ['Q161', 'Q256', 'Q161']),\n",
       " ('Q100032', ['Q161', 'Q233', 'Q161'])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(addresses_place_claims.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = geokb.models.References()\n",
    "refs.add(\n",
    "    geokb.datatypes.Item(\n",
    "        prop_nr=geokb.prop_lookup[\"data source\"],\n",
    "        value=\"Q54915\"\n",
    "    )\n",
    ")\n",
    "\n",
    "failures = []\n",
    "successes = []\n",
    "\n",
    "for item_qid, place_qids in addresses_place_claims.items():\n",
    "    item = geokb.wbi.item.get(item_qid)\n",
    "\n",
    "    place_claims = []\n",
    "    for place_qid in place_qids:\n",
    "        place_claims.append(\n",
    "            geokb.datatypes.Item(\n",
    "                prop_nr=geokb.prop_lookup['addresses place'],\n",
    "                value=place_qid,\n",
    "                references=refs\n",
    "            )\n",
    "        )\n",
    "\n",
    "    item.claims.add(place_claims, action_if_exists=geokb.action_if_exists.REPLACE_ALL)\n",
    "\n",
    "    try:\n",
    "        response = item.write(\n",
    "            summary=\"Added addresses place claims to publication from Pubs Warehouse country/state/county information that was successfully linked by name to GeoKB labels\"\n",
    "        )\n",
    "        print(f\"SUCCESS:{response.id}\")\n",
    "    except:\n",
    "        print(f\"FAILURE:{item_qid}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skybristol-skybristol-geokb",
   "language": "python",
   "name": "conda-env-skybristol-skybristol-geokb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
